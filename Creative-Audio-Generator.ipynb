{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install libs"
      ],
      "metadata": {
        "id": "9Eepfg2Xhy8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q gradio soundfile numpy scipy sqlalchemy python-dotenv pydub librosa requests\n",
        "# Optional heavy libs if you want HF/transformers locally (GPU required)\n",
        "# !pip install -q transformers accelerate diffusers \"huggingface_hub>=0.10.0\" replicate openai sentence-transformers"
      ],
      "metadata": {
        "id": "wXjm_RDWht1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Imports and Setup\n",
        "\n",
        "Sab imports top pe laa raha hoon.\n",
        "Logger setup kar raha hoon (kyunki code mein logger use ho raha hai lekin define nahi).\n",
        "Constants (STORAGE_FOLDER etc.) define."
      ],
      "metadata": {
        "id": "5862Zayck5zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import uuid\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Set up directories and database\n",
        "STORAGE_FOLDER = Path(\"creative_audio_storage\")\n",
        "SOUND_FOLDER = STORAGE_FOLDER / \"sounds\"\n",
        "DB_FILE = STORAGE_FOLDER / \"records.db\"\n",
        "STORAGE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
        "SOUND_FOLDER.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Database connection for tracking creations\n",
        "db_conn = sqlite3.connect(DB_FILE, check_same_thread=False)\n",
        "db_cursor = db_conn.cursor()\n",
        "db_cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS creations (\n",
        "        creation_id TEXT PRIMARY KEY,\n",
        "        type TEXT,\n",
        "        description TEXT,\n",
        "        reference_audio TEXT,\n",
        "        output_file TEXT,\n",
        "        source TEXT,\n",
        "        timestamp REAL\n",
        "    )\n",
        "\"\"\")\n",
        "db_conn.commit()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W2rQZSSbk6qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Procedural Music Function\n",
        "\n",
        "create_background_tune function same rakha, sirf indentation fix ki.\n",
        "Added missing np and random usage (already imported)."
      ],
      "metadata": {
        "id": "79I5EFqwo_M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved procedural music creation function\n",
        "def create_background_tune(length_seconds: int = 25, tempo: int = 110, random_seed: int = None) -> str:\n",
        "    \"\"\"\n",
        "    Generates a procedural ambient tune using layered waveforms.\n",
        "    Upgraded with varying rhythms, multiple layers, and subtle effects.\n",
        "    \"\"\"\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "        np.random.seed(random_seed)\n",
        "    sample_rate = 22050  # Lowered for lighter files\n",
        "    time_array = np.linspace(0, length_seconds, int(sample_rate * length_seconds), endpoint=False)\n",
        "    # Chord progressions with variations\n",
        "    chord_bases = [\n",
        "        [261.63, 329.63, 392.00, 523.25],  # Extended C major\n",
        "        [293.66, 349.23, 440.00, 587.32],  # D minor 7th-ish\n",
        "        [329.63, 392.00, 493.88, 659.25],  # E minor add9\n",
        "        [349.23, 440.00, 523.25, 698.46],  # F major 7th\n",
        "    ]\n",
        "    tune = np.zeros_like(time_array)\n",
        "    section_length = len(time_array) // len(chord_bases)\n",
        "    for idx, chords in enumerate(chord_bases):\n",
        "        section_start = idx * section_length\n",
        "        section_end = section_start + section_length if idx < len(chord_bases) - 1 else len(time_array)\n",
        "        section_time = time_array[section_start:section_end]\n",
        "        wave = np.zeros_like(section_time)\n",
        "        for freq in chords:\n",
        "            variation = random.uniform(-2.0, 2.0)  # Slight detune for richness\n",
        "            wave += 0.25 * np.sin(2 * np.pi * (freq + variation) * section_time)\n",
        "        # Improved envelope: ADSR-like for each section\n",
        "        attack = int(len(section_time) * 0.1)\n",
        "        decay = int(len(section_time) * 0.1)\n",
        "        sustain = int(len(section_time) * 0.6)\n",
        "        release = len(section_time) - (attack + decay + sustain)\n",
        "        envelope = np.concatenate([\n",
        "            np.linspace(0, 1, attack),\n",
        "            np.linspace(1, 0.7, decay),\n",
        "            np.ones(sustain) * 0.7,\n",
        "            np.linspace(0.7, 0, release)\n",
        "        ])\n",
        "        tune[section_start:section_end] += wave * envelope\n",
        "    # Add light percussion layer\n",
        "    beat_interval = 60 / tempo\n",
        "    beat_samples = int(beat_interval * sample_rate)\n",
        "    for beat_pos in range(0, len(time_array), beat_samples):\n",
        "        if random.random() > 0.7:  # Random skips for variation\n",
        "            tune[beat_pos:beat_pos+100] += 0.1 * np.random.normal(0, 1, 100)  # Soft noise hit\n",
        "    # Simple echo effect\n",
        "    delay_kernel = np.exp(-np.linspace(0, 1.5, 600))\n",
        "    tune = np.convolve(tune, delay_kernel, mode=\"same\")\n",
        "    # Normalize and save\n",
        "    tune = tune / (np.max(np.abs(tune)) + 1e-10) * 0.75\n",
        "    file_path = SOUND_FOLDER / f\"tune_{int(time.time())}.wav\"\n",
        "    sf.write(str(file_path), tune.astype(np.float32), sample_rate)\n",
        "    return str(file_path)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l6XjU1yZpGx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Procedural Voice Function\n",
        "\n",
        "create_synthetic_vocal same, indentation fix."
      ],
      "metadata": {
        "id": "XX62Sykppraw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgraded procedural voice synthesis\n",
        "def create_synthetic_vocal(text_input: str, vocal_seed: int = None) -> str:\n",
        "    \"\"\"\n",
        "    Creates a melodic vocal from text, mapping words to pitch sequences.\n",
        "    Enhanced with vowel formants simulation and better timing.\n",
        "    \"\"\"\n",
        "    if vocal_seed is not None:\n",
        "        random.seed(vocal_seed)\n",
        "        np.random.seed(vocal_seed)\n",
        "    sample_rate = 22050\n",
        "    words = text_input.split()\n",
        "    num_words = len(words)\n",
        "    total_length = 3.0 + num_words * 0.15  # Adjusted for natural pacing\n",
        "    time_array = np.linspace(0, total_length, int(sample_rate * total_length), endpoint=False)\n",
        "    vocal_track = np.zeros_like(time_array)\n",
        "    segment_duration = len(time_array) // max(1, num_words)\n",
        "    for word_idx, word in enumerate(words):\n",
        "        base_pitch = 200 + (word_idx % 10) * 25  # Varied scale\n",
        "        segment_start = word_idx * segment_duration\n",
        "        segment_end = min(len(time_array), (word_idx + 1) * segment_duration)\n",
        "        segment_length = segment_end - segment_start\n",
        "        if segment_length <= 0:\n",
        "            continue\n",
        "        segment_time = np.linspace(0, segment_length / sample_rate, segment_length, endpoint=False)\n",
        "        # Simulate formants for vowel-like sound\n",
        "        formant1 = np.sin(2 * np.pi * base_pitch * segment_time)\n",
        "        formant2 = 0.6 * np.sin(2 * np.pi * (base_pitch * 1.5 + random.uniform(-10, 10)) * segment_time)\n",
        "        formant3 = 0.3 * np.sin(2 * np.pi * (base_pitch * 2.2 + random.uniform(-15, 15)) * segment_time)\n",
        "        combined = formant1 + formant2 + formant3\n",
        "        # Envelope for each word: smoother curve\n",
        "        envelope = np.sin(np.pi * np.linspace(0, 1, segment_length)) ** 2  # Raised sine for swell\n",
        "        vocal_track[segment_start:segment_end] += combined * envelope * 0.6\n",
        "    # Add light vibrato globally\n",
        "    vibrato = 1 + 0.02 * np.sin(2 * np.pi * 5 * time_array)  # 5Hz vibrato\n",
        "    vocal_track *= vibrato\n",
        "    # Normalize and add subtle noise for realism\n",
        "    vocal_track += 0.005 * np.random.randn(len(vocal_track))\n",
        "    vocal_track = vocal_track / (np.max(np.abs(vocal_track)) + 1e-10) * 0.8\n",
        "    file_path = SOUND_FOLDER / f\"vocal_{int(time.time())}.wav\"\n",
        "    sf.write(str(file_path), vocal_track.astype(np.float32), sample_rate)\n",
        "    return str(file_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AMA3Vh2lpzK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Placeholder Functions for Advanced Generation\n"
      ],
      "metadata": {
        "id": "-AZQkm5IqbQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder for advanced music generation (e.g., via API)\n",
        "def advanced_tune_generation(desc: str, length: int = 15) -> str:\n",
        "    \"\"\"\n",
        "    Stub for integrating external music API (e.g., custom endpoint).\n",
        "    For now, falls back to procedural.\n",
        "    \"\"\"\n",
        "    # In a real setup, call API here\n",
        "    logger.info(\"Using fallback procedural for advanced tune\")\n",
        "    return create_background_tune(length_seconds=length)\n",
        "\n",
        "# Placeholder for advanced voice generation\n",
        "def advanced_vocal_generation(text: str, ref_audio: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Stub for external voice synthesis API.\n",
        "    Falls back to procedural.\n",
        "    \"\"\"\n",
        "    logger.info(\"Using fallback procedural for advanced vocal\")\n",
        "    return create_synthetic_vocal(text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f2pVQD8_qe8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: DB Logging Function\n",
        "\n",
        "SQL placeholders."
      ],
      "metadata": {
        "id": "-lkkNnAcqxCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Record creation in DB\n",
        "def log_creation(entry_type: str, desc: str, output: str, source: str = \"local\", ref: str = None) -> str:\n",
        "    entry_id = str(uuid.uuid4())\n",
        "    now = time.time()\n",
        "    db_cursor.execute(\n",
        "        \"INSERT INTO creations (creation_id, type, description, reference_audio, output_file, source, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?)\",\n",
        "        (entry_id, entry_type, desc, ref, output, source, now)\n",
        "    )\n",
        "    db_conn.commit()\n",
        "    return entry_id"
      ],
      "metadata": {
        "id": "IhjLr4vtq3oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: UI Handler Functions\n",
        "\n",
        "Added type checks for ref_upload."
      ],
      "metadata": {
        "id": "qVbvBkkDrBzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UI handler for tune generation\n",
        "def handle_tune_creation(desc, length, advanced_mode):\n",
        "    try:\n",
        "        if advanced_mode:\n",
        "            file = advanced_tune_generation(desc, length=int(length))\n",
        "            src = \"advanced\"\n",
        "        else:\n",
        "            file = create_background_tune(length_seconds=int(length))\n",
        "            src = \"local\"\n",
        "        entry_id = log_creation(\"tune\", desc, file, src)\n",
        "        return f\"Tune created successfully (ID: {entry_id}) with {src} method\", file\n",
        "    except Exception as err:\n",
        "        logger.error(f\"Tune creation failed: {err}\")\n",
        "        return f\"Failed to create tune: {str(err)}\", None\n",
        "\n",
        "# UI handler for vocal generation\n",
        "def handle_vocal_creation(text, ref_upload, advanced_mode):\n",
        "    try:\n",
        "        ref_path = None\n",
        "        if ref_upload is not None:\n",
        "            if isinstance(ref_upload, tuple) and len(ref_upload) == 2:  # (sr, data)\n",
        "                sr, data = ref_upload\n",
        "                ref_path = SOUND_FOLDER / f\"ref_{int(time.time())}.wav\"\n",
        "                sf.write(str(ref_path), np.array(data), sr)\n",
        "            elif isinstance(ref_upload, str) and os.path.exists(ref_upload):\n",
        "                ref_path = SOUND_FOLDER / f\"ref_copy_{int(time.time())}.wav\"\n",
        "                shutil.copy(ref_upload, ref_path)\n",
        "        if advanced_mode:\n",
        "            file = advanced_vocal_generation(text, ref_path=str(ref_path) if ref_path else None)\n",
        "            src = \"advanced\"\n",
        "        else:\n",
        "            file = create_synthetic_vocal(text)\n",
        "            src = \"local\"\n",
        "        entry_id = log_creation(\"vocal\", text, file, src, str(ref_path) if ref_path else None)\n",
        "        return f\"Vocal created successfully (ID: {entry_id}) with {src} method\", file\n",
        "    except Exception as err:\n",
        "        logger.error(f\"Vocal creation failed: {err}\")\n",
        "        return f\"Failed to create vocal: {str(err)}\", None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fclW84eLrFkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Gradio Interface Function and Main Block\n",
        "\n",
        "Added theme to Gradio, fixed name == \"main\"."
      ],
      "metadata": {
        "id": "IV8qa4lvriYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xP8qVLamc2g6"
      },
      "outputs": [],
      "source": [
        "# Construct and start the interface\n",
        "def start_interface(public_share: bool = True, open_browser: bool = False):\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as interface:\n",
        "        gr.Markdown(\"# Creative Audio Tool - Enhanced Edition\")\n",
        "\n",
        "        with gr.Tab(\"Tune Creator\"):\n",
        "            tune_desc = gr.Textbox(lines=4, label=\"Describe the tune (e.g., upbeat synthwave with drums)\", value=\"Relaxing piano melody with soft strings\")\n",
        "            tune_length = gr.Slider(10, 90, value=30, step=5, label=\"Length in seconds\")\n",
        "            use_advanced_tune = gr.Checkbox(label=\"Enable advanced generation (if configured)\", value=False)\n",
        "            create_tune_btn = gr.Button(\"Create Tune\")\n",
        "            tune_status = gr.Textbox(label=\"Result\")\n",
        "            tune_output = gr.Audio(label=\"Your Tune\")\n",
        "\n",
        "        with gr.Tab(\"Vocal Creator\"):\n",
        "            vocal_text = gr.Textbox(lines=4, label=\"Text or lyrics for vocal\", value=\"Welcome to the future of sound creation.\")\n",
        "            vocal_ref = gr.Audio(type=\"numpy\", label=\"Optional reference audio for style\")\n",
        "            use_advanced_vocal = gr.Checkbox(label=\"Enable advanced vocal synthesis (if configured)\", value=False)\n",
        "            create_vocal_btn = gr.Button(\"Create Vocal\")\n",
        "            vocal_status = gr.Textbox(label=\"Result\")\n",
        "            vocal_output = gr.Audio(label=\"Your Vocal\")\n",
        "\n",
        "        create_tune_btn.click(\n",
        "            fn=handle_tune_creation,\n",
        "            inputs=[tune_desc, tune_length, use_advanced_tune],\n",
        "            outputs=[tune_status, tune_output]\n",
        "        )\n",
        "\n",
        "        create_vocal_btn.click(\n",
        "            fn=handle_vocal_creation,\n",
        "            inputs=[vocal_text, vocal_ref, use_advanced_vocal],\n",
        "            outputs=[vocal_status, vocal_output]\n",
        "        )\n",
        "\n",
        "    interface.launch(share=public_share, inbrowser=open_browser)\n",
        "    print(\"Interface is running. Check for the Gradio URL if in a notebook.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_interface(public_share=True, open_browser=False)"
      ]
    }
  ]
}